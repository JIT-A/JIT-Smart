{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from focal_loss import BinaryFocalLoss, MultiFocalLoss\n",
    "from torch.nn import CrossEntropyLoss, MSELoss, BCELoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from   torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "batch_size, num_class = 16, 2\n",
    "Loss_Func = MultiFocalLoss(num_class=num_class, gamma=2.0, reduction='mean')\n",
    "\n",
    "logits = torch.rand(batch_size, num_class, requires_grad=True)  # (batch_size, num_classes)\n",
    "targets = torch.randint(0, num_class, size=(batch_size, ))  # (batch_size, )\n",
    "\n",
    "loss = Loss_Func(logits, targets)\n",
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1]) torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "# loss_fct = BinaryFocalLoss()\n",
    "loss_fct = BCELoss()\n",
    "batch_size, num_class = 16, 1\n",
    "pred = torch.rand(batch_size, num_class, requires_grad=True)  # (batch_size, num_classes)\n",
    "labels = torch.randint(0, num_class+1, size=(batch_size, ))  # (batch_size, )\n",
    "labels = labels.unsqueeze(1).float()\n",
    "print(pred.shape, labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.2944, grad_fn=<BinaryCrossEntropyBackward>)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n",
      "tensor([[0.0000],\n",
      "        [0.0227],\n",
      "        [0.0000],\n",
      "        [0.0227]])\n",
      "torch.Size([4, 1])\n",
      "tensor([[0.0433],\n",
      "        [0.0000],\n",
      "        [0.0433],\n",
      "        [0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(0.0330)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred1 = torch.tensor([[0.5,0.5],[0.3,0.7],[1,0],[1,0]]).float()\n",
    "# pred1 = torch.tensor([[0.1,0,1,0]]).float()\n",
    "# pred1 = torch.tensor([[1],[0],[1],[0]]).float()\n",
    "pred1 = torch.tensor([[0],[1],[0],[1]]).float()\n",
    "labels1 = torch.tensor([0,1,0,1]).float()\n",
    "loss_fct = BinaryFocalLoss(alpha=0.25, gamma=2, reduction='mean')\n",
    "loss1 = loss_fct(pred1, labels1)\n",
    "loss1\n",
    "\n",
    "# labels2 = torch.tensor([1,1,1,1]).float()\n",
    "# print(pred1.shape, labels1.shape, labels2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(0.1755)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 = torch.tensor([[1,0],[0,1],[1,0],[0,1]]).float()\n",
    "pred1 = torch.tensor([[0,1],[1,0],[0,1],[1,0]]).float()\n",
    "labels1 = torch.tensor([0,1,0,1])\n",
    "print(pred1.shape, labels1.shape)\n",
    "loss_fct = MultiFocalLoss(alpha=0.25, gamma=2, reduction='mean', num_class=2)\n",
    "loss1 = loss_fct(pred1, labels1)\n",
    "loss1\n",
    "\n",
    "# loss = loss_fct(pred, labels)\n",
    "# loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n",
      "tensor([[0.0000],\n",
      "        [0.0227],\n",
      "        [0.0000],\n",
      "        [0.0227]])\n",
      "torch.Size([4, 1])\n",
      "tensor([[0.1733],\n",
      "        [0.0000],\n",
      "        [0.1733],\n",
      "        [0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(0.0980)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_fct = BinaryFocalLoss(alpha=0.25, gamma=2, reduction='mean')\n",
    "loss1 = loss_fct(pred1, labels1)\n",
    "loss1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "tensor([[0.1733, 0.0227],\n",
      "        [0.0227, 0.1733],\n",
      "        [0.0227, 0.1733],\n",
      "        [0.0227, 0.1733]])\n",
      "torch.Size([4, 2])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(0.0980)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2 = loss_fct(pred1, labels2)\n",
    "loss2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([8, 2]), torch.Size([8]))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "num_class=2\n",
    "logits = torch.rand(batch_size, num_class, requires_grad=True)  # (batch_size, num_classes)\n",
    "targets = torch.randint(0, num_class, size=(batch_size, ))  # (batch_size, )\n",
    "logits.shape, targets.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(4,4)\n",
    "x\n",
    "x.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7491,  0.6891],\n",
      "        [-1.7619, -1.0933]])\n",
      "tensor([[0.5150, 0.4850],\n",
      "        [0.3388, 0.6612]])\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7491, 0.6891]),\n",
      "indices=tensor([0, 0]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input = torch.randn(2, 2)\n",
    "print(input)\n",
    "\n",
    "b = torch.softmax(input, dim=1)  # 按列SoftMax,列和为1\n",
    "print(b)\n",
    "b = torch.max(input, dim=0)  # 按列Max\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[:,1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 1])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[0.1], [0.2], [0.9]])\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 2])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat([x, 1-x], dim=1)\n",
    "\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0],\n        [0, 0],\n        [0, 0]], dtype=torch.int32)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.int()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "torch.softmax([])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n",
    "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer, RobertaModel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(50267, 768)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = '../../microsoft/codebert-base'\n",
    "config = RobertaConfig.from_pretrained(model_name)\n",
    "config.num_labels = 2\n",
    "config.feature_size = 14\n",
    "config.hidden_dropout_prob = 0.1\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "special_tokens_dict = {'additional_special_tokens': [\"[ADD]\", \"[DEL]\"]}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "model = RobertaModel.from_pretrained(model_name, config=config)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "emb = model.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "50267"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.num_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "768"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.embedding_dim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 10, 768])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(1,10,(4,10))\n",
    "\n",
    "y = emb(x)\n",
    "y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 10])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class Attention(nn.Module):       #x:[batch, seq_len, hidden_dim*2]\n",
    "    \"\"\"\n",
    "        此注意力的计算步骤：\n",
    "        1.将输入（包含lstm的所有时刻的状态输出）和w矩阵进行矩阵相乘，然后用tanh压缩到(-1, 1)之间\n",
    "        2.然后再和矩阵u进行矩阵相乘后，矩阵变为1维，然后进行softmax变化即得到注意力得分。\n",
    "        3.将输入和此注意力得分线性加权，即相当于将所有时刻的状态进行了一个聚合。\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, need_aggregation=True):\n",
    "        super().__init__()\n",
    "        self.need_aggregation = need_aggregation\n",
    "        # 不双向的话就不用乘2\n",
    "        self.w = nn.Parameter(torch.Tensor(hidden_size * 2, hidden_size * 2))\n",
    "        self.u = nn.Parameter(torch.Tensor(hidden_size * 2, 1))\n",
    "        nn.init.uniform_(self.w, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.u, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        self.w = self.w.to(device)\n",
    "        self.u = self.u.to(device)\n",
    "\n",
    "        u = torch.tanh(torch.matmul(x, self.w))         #[batch, seq_len, hidden_size*2]\n",
    "        score = torch.matmul(u, self.u)                   #[batch, seq_len, 1]\n",
    "        att = F.softmax(score, dim=1)\n",
    "        # 下面操作即线性加权\n",
    "        scored_x = x * att                              #[batch, seq_len, hidden_size*2]\n",
    "\n",
    "        # 因为词encoder和句encoder后均带有attention机制，而我需要做的是代码行级缺陷检测，\n",
    "        # 所以句encoder后我不做聚合，相当于将每个代码行看做一个样本来传入全连接分类。\n",
    "        if self.need_aggregation:\n",
    "            context = torch.sum(scored_x, dim=1)                  #[batch, hidden_size*2]\n",
    "            return context\n",
    "        else:\n",
    "            return scored_x\n",
    "\n",
    "\n",
    "\n",
    "class HAN_MODEL(nn.Module):\n",
    "    def __init__(self, embedding_layer):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 1\n",
    "        self.bidirectional = True\n",
    "\n",
    "        self.embedding = embedding_layer\n",
    "\n",
    "\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=self.embedding.embedding_dim,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            bidirectional=self.bidirectional,\n",
    "                            batch_first=True)\n",
    "        self.att1 = Attention(self.hidden_size, need_aggregation=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.hidden_size*2,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            bidirectional=self.bidirectional,\n",
    "                            batch_first=True)\n",
    "        self.att2 = Attention(self.hidden_size, need_aggregation=True)\n",
    "\n",
    "        # 代码行级分类输出层，代码有多少行，输出就有多少个神经元\n",
    "        # self.fc1 = nn.Linear(512, 2)\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.relu = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        # self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input x : (bs, nus_sentences, nums_words)\n",
    "        device = x.device\n",
    "        x = self.embedding(x) # out x : (bs, nus_sentences, nums_words, embedding_dim)\n",
    "        batch_size, num_sentences, num_words, emb_dim = x.shape\n",
    "\n",
    "        # 初始化：双向就乘2\n",
    "        h0_1 = torch.randn(self.num_layers*2, batch_size*num_sentences, self.hidden_size).to(device)\n",
    "        c0_1 = torch.randn(self.num_layers*2, batch_size*num_sentences, self.hidden_size).to(device)\n",
    "        h0_2 = torch.randn(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "        c0_2 = torch.randn(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        # 先进入word的处理，将每句话的所有单词的表示通过attention聚合成一个表示\n",
    "        # 将batch_size, num_sentences两个维度乘起来看成“batch_size”。使用.contiguous()方法首先拷贝了一份张量在内存中的地址，然后将地址按照形状改变后的张量的语义进行排列。\n",
    "        # touch.view()方法对张量改变“形状”其实并没有改变张量在内存中真正的形状\n",
    "        x = x.view(batch_size*num_sentences, num_words, emb_dim).contiguous()\n",
    "        x,(_,_)= self.lstm1(x, (h0_1,c0_1))   # out：batch_size*num_sentences, num_words，hidden_size*2\n",
    "        x = self.att1(x)   # 线性加权注意力后的输出：batch_size*num_sentences, hidden_size*2\n",
    "\n",
    "        x = x.view(x.size(0)//num_sentences, num_sentences, self.hidden_size*2).contiguous()\n",
    "        x,(_,_)= self.lstm2(x, (h0_2,c0_2))   # out：batch_size, num_sentences，hidden_size*2\n",
    "\n",
    "        x = self.att2(x)   # 线性加权注意力后的输出：batch_size, hidden_size*2\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "model = HAN_MODEL(embedding_layer=emb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 2])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size, num_sentences, num_words, embedding_dim\n",
    "# 类比CV：batch_size, W, H, C\n",
    "x  = torch.ones(64, 100, 20).long()\n",
    "out = model(x)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100, 20, 300])\n"
     ]
    }
   ],
   "source": [
    "x  = torch.ones(64, 100, 20).long()\n",
    "embedding = nn.Embedding(1000, 300)\n",
    "out = embedding(x)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}